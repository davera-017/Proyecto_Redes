{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T02:46:35.745450Z",
     "start_time": "2021-09-06T02:46:35.738681Z"
    }
   },
   "outputs": [],
   "source": [
    "#PAQUETES \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os\n",
    "\n",
    "# tweeter processing\n",
    "# Import all needed libraries\n",
    "import tweepy                   # Python wrapper around Twitter API\n",
    "import json\n",
    "import csv\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import time\n",
    "import webbrowser\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T03:05:10.994040Z",
     "start_time": "2021-09-06T03:05:10.986242Z"
    }
   },
   "outputs": [],
   "source": [
    "base_dir = Path.cwd()\n",
    "data_dir = base_dir / 'data'\n",
    "#Create if they don't exist\n",
    "Path(data_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T02:46:36.246005Z",
     "start_time": "2021-09-06T02:46:36.240146Z"
    }
   },
   "outputs": [],
   "source": [
    "consumer_key = 'eIVPmXDdEYEtvfJaPLtJD12iV'\n",
    "consumer_secret = 'aOnHd3rwXOgL2hsmuOXVtGP51NBePNHmovGDRGnKGQSwN6iMQZ'\n",
    "\n",
    "access_token = '1386719422971355137-pd3S7pBWRLEjXwzI1qRz67Sz9txP9I'\n",
    "access_token_secret = 'qYqySGmFSJGNVlZYSvr02kjyMmxMWOuORKCKglL5T3C5p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T02:46:36.622994Z",
     "start_time": "2021-09-06T02:46:36.608190Z"
    }
   },
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:28:30.760592Z",
     "start_time": "2021-09-06T04:28:30.723040Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_query(query):\n",
    "    # initialize a list to hold all the Tweets\n",
    "    alltweets = []\n",
    "    data = pd.DataFrame(columns=['tweet_id', 'user_id', 'name', 'screen_name', 'followers_count', 'retweet_count', 'likes_count', 'text', 'mined_at', 'created_at', 'favourite_count', 'retweet_text', 'retweet_user_id', 'retweet_screen_name', 'quote_text', 'quote_user_id', 'quote_screen_name'])\n",
    "    #name\n",
    "    print(f'–– {query} –– \\n')\n",
    "    \n",
    "    #time \n",
    "    t0 = time.time()\n",
    "    \n",
    "    # make initial request for most recent tweets \n",
    "    # (200 is the maximum allowed count)\n",
    "    new_tweets = api.search(query, result_type='recent', lang='es', count=200, tweet_mode=\"extended\")\n",
    "    \n",
    "    # save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    #print(f\"...{len(alltweets)} tweets downloaded so far... {round(time.time() - t0)} s\")\n",
    "    # save the id of the oldest tweet less one to avoid duplication\n",
    "    \n",
    "    oldest = alltweets[-1].id - 1\n",
    "    delta_delta = 0\n",
    "    # keep grabbing tweets until there are no tweets left\n",
    "    while len(new_tweets) > 0:\n",
    "        # all subsequent requests use the max_id param to prevent\n",
    "        # duplicates\n",
    "        new_tweets = api.search(query, result_type='recent', lang='es', count=200, max_id=oldest, tweet_mode=\"extended\")\n",
    "        # save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "        # update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        \n",
    "        delta_t = round(time.time() - t0)\n",
    "        if delta_t >= (delta_delta +10):\n",
    "            delta_delta = delta_t\n",
    "            print(f\"...{len(alltweets)} tweets downloaded so far... {delta_t} s\")\n",
    "        ### END OF WHILE LOOP ###\n",
    "        \n",
    "    # transform the tweepy tweets into a dictionary\n",
    "    for tweet in alltweets:\n",
    "        mined = {\n",
    "            'tweet_id':        tweet.id,\n",
    "            'user_id':         tweet.user.id,\n",
    "            'name':            tweet.user.name,\n",
    "            'screen_name':     tweet.user.screen_name,\n",
    "            'followers_count': tweet.user.followers_count,\n",
    "            'retweet_count':   tweet.retweet_count,\n",
    "            'likes_count':     tweet.favorite_count,\n",
    "            'text':            tweet.full_text,\n",
    "            'mined_at':        datetime.now(),\n",
    "            'created_at':      tweet.created_at,\n",
    "            'favourite_count': tweet.favorite_count\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            mined['retweet_text'] = tweet.retweeted_status.full_text\n",
    "            mined['retweet_user_id'] = tweet.retweeted_status.user.id\n",
    "            mined['retweet_screen_name'] = tweet.retweeted_status.user.screen_name\n",
    "        except:\n",
    "            mined['retweet_text'] = 'None'\n",
    "            mined['retweet_user_id'] = 'None'\n",
    "            mined['retweet_screen_name'] = 'None'\n",
    "        try:\n",
    "            mined['quote_text'] = tweet.quoted_status.full_text\n",
    "            mined['quote_user_id'] = tweet.quoted_status.user.id\n",
    "            mined['quote_screen_name'] = tweet.quoted_status.user.screen_name\n",
    "        except:\n",
    "            mined['quote_text'] = 'None'\n",
    "            mined['quote_user_id'] = 'None'\n",
    "            mined['quote_screen_name'] = 'None'\n",
    "    \n",
    "        data = data.append(mined, ignore_index=True)\n",
    "        \n",
    "    print(f'\\n TIEMPO TOTAL: {round(time.time() - t0)} s \\n')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:20:48.226221Z",
     "start_time": "2021-09-06T04:20:48.218599Z"
    }
   },
   "outputs": [],
   "source": [
    "afavor_HTS = ['abortolegalya','CausaJustaTV','SaludReproductivaAhora','LaLibertadEsMiCausa','DerechoAlaIVE','micausajusta','CausaJusta','DerechoALaIVE','CausaJustaPorElAborto','LaLibertadEsMiCausa','CorteAbortoSi']\n",
    "encontra_HTS = ['sialavida','noalaborto','nohayabortoseguro','yosoyprovida','soyprovida','colombiaesprovida','salvemoslas2vidas','abortoinconstitucional','noseráley','noseraley','CorteAbortoNo']\n",
    "HTS = dict(aliados=afavor_HTS, opositores=encontra_HTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T04:34:06.468905Z",
     "start_time": "2021-09-06T04:34:06.440277Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def queries_to_df(dicc_queries):\n",
    "    dfs = []\n",
    "    for q in dicc_queries:\n",
    "        query = ['#'+x for x in HTS[q]]\n",
    "        query = ' OR '.join(query)\n",
    "\n",
    "        d = get_query(query)\n",
    "        d['orientation'] = q\n",
    "        dfs.append(d)\n",
    "        d =None\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    df.to_pickle(data_dir / 'tweets.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
